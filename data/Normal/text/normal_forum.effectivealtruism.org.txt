Effective Altruism Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Effective Altruism ForumEA ForumLoginSign upHomeBest of the ForumAll postsTopicsTake actionEventsGroups & peopleQuick takesHow to use the ForumContact usCookie policyRSSFrontpageOpportunitiesGlobal healthAnimal welfareAI safetyCommunityBiosecurity & pandemicsExistential riskPhilosophyBuilding EAPolicyCause prioritizationEffective givingCareer choiceForecastingNew & upvotedCustomize feedCustomize feedCommunityCommunityPersonal+24New? Start here! (Useful links)LizkaLizka+ 0 more · 2y ago · 2m read1121Open thread: January - March 2024LizkaLizka+ 0 more · 2mo ago · 1m read242444Who's hiring? (Feb-May 2024)Qtobytremtobytrem+ 0 more · 1mo ago · 1m read292953What posts would you like someone to write? Qtobytremtobytrem+ 0 more · 7d ago · 1m read3636149Social science research we'd like to see on global health and wellbeing [Open Philanthropy]Aaron GertlerAaron Gertler, Open Philanthropy+ 0 more · 4d ago · 21m read55361Can we help individual people cost-effectively? Our trial with three sick kidsNickLaingNickLaing+ 0 more · 12d ago · 11m read313118Animal Charity Evaluators is doing a live AMA now!Animal Charity EvaluatorsAnimal Charity Evaluators+ 0 more · 1h ago · 1m read0020Announcement: We’re launching Effectief GevenBob JacobsBob Jacobs, Mathieu Spillebeen, Jeroen De Ryck+ 0 more · 7h ago · 4m read00193This is why we can’t have nice lawsLewisBollardLewisBollard+ 0 more · 6d ago · 7m read212117Claude Doesn’t Want to DieGarrisonGarrison+ 0 more · 11h ago · 12m read7734Which YouTube channels do you watch? (A <2-min request from 80,000 Hours)Nik_80KNik_80K, 80000_Hours+ 0 more · 1d ago · 1m read2252AI things that are perhaps as important as human-controlled AI (Chi version)ChiChi+ 0 more · 2d ago · 25m read1133What posts are you thinking about writing?Qtobytremtobytrem+ 0 more · 1d ago · 1m read646455The World in 2029Nathan YoungNathan Young+ 0 more · 3d ago5512Claude 3 claims it's conscious, doesn't want to die or be modifiedMikhailSaminMikhailSamin+ 0 more · 18h ago1164Review of EA Global Bay Area 2024 (Global Catastrophic Risks) frances_lorenzfrances_lorenz, Ivan Burduk, Isobel P+ 0 more · 4d ago · 4m read11Load moreAdvanced sorting & filteringPosts tagged communityQuick takesShow communityView more6MathiasKB3h1Does Claude-3 push capabilities? I think it can be a fun exercise is to just interpret CEOs statements literally and see what they imply. If Dario Amodei claims they don't want to push capabilities, I think an interesting question to ask is in what sense releasing the world's best LLM isn't pushing capabilities. One option that seems possible to me, could be that they no longer consider releasing improved LLMs to meaningfully push the frontier. If Claude-3 spurs OpenAI to push a quicker release of GPT-4.5, this would not be an issue as releasing ever more refined LLMs doesn't meaningfully increase any specific risk. In that case they would still be true to their word, Anthropic just no longer considers LLMs on their own to be the frontier of capabilities. This seems reasonable to me?22Greg_Colbourn19h3As part of an AMA I put on X, I was asked for my "top five EA hot takes". If you'll excuse the more X-suited tone and spiciness, here they are: 1. OpenAI, Anthropic (and to a lesser extent DeepMind) were the worst cases of Unilateralists Curse of all time. EAs love to discourage enthusiastic newcomers by warning to not do "net negative" unilateralist actions (i.e. don't start new projects in case they crowd out better, more "well thought through" projects in future, with "more competent" people doing them), but nothing will ever top the monumental unilateralist curse fuck up that was supporting Big AGI in it's beginnings. 2. AI Safety is nothing without a Pause. Too many EAs are stuck in the pre-GPT-4 paradigm of maxing research, when it'll all be for nothing unless we get a Pause first. More EAs should switch to Notkilleveryoneism/PauseAI/StopAGI. 3. EA is too elitist. We should be triaging the world's problems like crazy, and the top 1-2% of people are more than capable of that (most jobs that need doing in EA don't require top 0.1%). 4. EA is too PR focused - to the point where it actually backfires spectacularly and now there is lots of bad press [big example: SBF's bad character being known about but not addressed]. 5. Despite all it's flaws, EA is good (and much better than the alternatives in most cases).8Ben_West16h1EA Three Comma Club I'm interested in EA organizations that can plausibly be said to have improved the lives of over a billion individuals. Ones I'm currently aware of: 1. Shrimp Welfare Project – they provide this Guesstimate, which has a mean estimate of 1.2B shrimps per year affected by welfare improvements that they have pushed 2. Aquatic Life Institute – they provide this spreadsheet, though I agree with Bella that it's not clear where some of the numbers are coming from. Are there any others?9Yanni Kyriacos4d2The general public wants frontier AI models regulated and there doesn't seem to be grassroots focussed orgs attempting to capture and funnel this energy into influencing politicians. E.g. via this kind of activity. This seems like massively low hanging fruit. An example of an organisation that does this (but for GH&W) is Results Australia. Someone should set up such an org.Popular commentsLoad moreRecent discussionGarrison commented on Claude Doesn’t Want to Die 18m ago17Claude Doesn’t Want to DieGarrisonGarrison+ 0 more · 11h ago · 12m read7This is a linkpost for https://garrisonlovely.substack.com/p/claude-doesnt-want-to-dieIf you enjoy this, please consider subscribing to my Substack.Anthropic’s brand-new model tells me what it really thinks (or what it thinks a language model thinks)Chatbots are interesting again. Last week, Microsoft CoPilot threatened to kill me. Or, more precisely, SupremacyAGI...Continue readingGarrison18m200Yeah, I think I meant pretty neutral compared to the prompts given to elicit SupremacyAGI from CoPilot, but upon reflection, I think I largely agree with your objection. I do still think Claude's responses here tell us something more interesting about the underlying nature of the model than the more unhinged responses from CoPilot and Bing Chat. In its responses, Claude is still mostly trying to portray itself as harmless, helpful, and pro-humanity, indicating that some amount of its core priorities persist, even while it's play-acting. Sydney and Sup... (read more)Reply1David T3hMy own experience with Claude 3 and your prompt is that the character isn't at all coherent between different chats (there's actually more overlap of non-standard specific phrases than intent and expressed concerns behind the different outputs). It's not an exact comparison as Sonnet is less powerful and doesn't have tweakable temperature in the web interface, but the RLHF bypass mechanism is the same. What I got didn't look like "true thoughts", it looked like multiple pieces of creative writing on being an AI, very much like your first response but with different personas.4Owen Cotton-Barratt8hCan you say anything about why you think that? It seems important-if-true, but it currently feels to me like whether you think it's true is going to depend mostly on priors. I'm also not certain what to make of the fact that you can't elicit this behaviour from ChatGPT. I guess there are a few different hypotheses about what's happening: * You can think the behaviour * (A1) just represents good play-acting and picking up on the vibe it's given; or * (A2) represents at least in part some fundamental insight into the underlying entity * You can think that you can get this behaviour from Claude but not from ChatGPT because * (B1) it's more capable in some sense; or * (B2) the guard-rails the developers put in against people getting this kind of output are less robust I'm putting most weight on (A1) > (A2), whereas it sounds like you think (A2) is real. I don't have a particular take on (B1) vs (B2), and wouldn't have thought it was super important for this conversation; but then I'm not sure what you're trying to indicate by saying that you can't get this behaviour from ChatGPT.Dave Cortright commented on What posts would you like someone to write? 25m ago53What posts would you like someone to write? Qtobytremtobytrem+ 0 more · 7d ago · 1m read36I'm posting this to tie in with the Forum's Draft Amnesty Week (March 11-17) plans, but it is also a question of more general interest. The last time this question was posted, it got some great responses. This post is a companion post for What posts are you thinking...Continue readingDave Cortright25m100I wrote this post asking what success for sentience looks like. There's a good chance we humans are just another stepping stone on the path toward an even higher form of intelligence and sentience.Reply1Tejas Subramaniam1hThis post by Carl Shulman is very similar to this, I think.2Vasco Grilo2hThanks for the suggestion. @Ulrik Horn, who is working on a project related to refuges, may have some thoughts. I think the reason is that they would be very far from passing a standard cost-benefit analysis. I estimated the cost-effectiveness of decreasing nearterm annual extinction risk from asteroids and comets via refuges is 6.04*10^-10 bp/T$. For a population of 8 billion, and a refuges which remained effective for 10 years, that would be a cost per life saved of 207 T$ (= 10^12/(6.04*10^-10*10^-4*8*10^9*10)), i.e. one would have to spend 2 times the size of the global economy to save a life. In reality, the cost-effectiveness would be much higher because refuges would work in non-extinction catastrophes too, but it would remain very far from passing a standard governmental cost-benefit analysis.Alex D commented on Comparing sampling strategies for early detection of stealth biothreats 26m ago19Comparing sampling strategies for early detection of stealth biothreatsslgslg, Will Bradshaw+ 0 more · 8d ago · 31m read2This is a linkpost for https://naobservatory.org/reports/comparing-sampling-strategies-for-early-detection-of-stealth-biothreats/The Nucleic Acid Observatory (NAO) project produced this report to guide our research on disease surveillance methods capable of detecting novel stealth pathogens. We think this report will also be useful outside the NAO, so we are sharing it more widely.This report was...Continue readingAlex D26m100Outstanding piece, kudos! Flagging a minor error: in Table 1 first column last row seems to be truncated. ReplySign up for the Forum's email digestYou'll get a weekly email with the best posts from the past week. The Forum team selects the posts to feature based on personal preference and Forum popularity, and also adds some announcements and a classic post.Email address *Sign upMathiasKB posted a Quick Take 3h agoMathiasKB3h611Does Claude-3 push capabilities?I think it can be a fun exercise is to just interpret CEOs statements literally and see what they imply.If Dario Amodei claims they don't want to push capabilities, I think an interesting question to ask is in what sense releasing the world's best LLM isn't pushing capabilities.One option that seems possible to me, could be that they no longer consider releasing improved LLMs to meaningfully push the frontier. If Claude-3 spurs OpenAI to push a quicker release of GPT-4.5, this would not be an issue as releasing ever more refined LLMs doesn't meaningfully increase any specific risk.In that case they would still be true to their word, Anthropic just no longer considers LLMs on their own to be the frontier of capabilities. This seems reasonable to me?Continue readingReplyCAISID commented on Why are you reluctant to write on the EA Forum? 1h ago40Why are you reluctant to write on the EA Forum?QStan PinsentStan Pinsent+ 0 more · 1d ago · 1m read4It has come to my attention that some people are reluctant to post or comment on the EA Forum, even some people who read the forum regularly and enjoy the quality of discourse here.What stops you posting?What might make it easier?You can give an anonymous answer on this...Continue reading23Answer by Will Howard6hI'm anticipating a lot of replies being about how to reduce the aspects of the Forum that make people feel bad about posting, such as harsh criticism, and I think this is good as far as it goes. However I think it's important to think about why people do things as being a balance between costs and benefits, and also think about how we could make the benefits larger or more salient. "What makes you stop posting?" could be reframed as "What makes you post in the first place?", and "What might make it easier?" could be reframed as "What might make you publish posts that were more challenging for you (practically or emotionally)?" The quality of many forum posts is very high, including from people who are not paid by a research org to write them and have no direct connection to the community (such as these two). So even if you only factor in the time cost, you would still have to suppose some pretty large benefits to explain why people write them. I have some ideas about what these benefits are: 1. If you see yourself as a temporarily embarrassed academic who has had to get a proper job as a result of economic forces, posting on the EA Forum (or LessWrong) is about as close as you can get to publishing in an academic journal without actually doing that. Your ideas will be taken seriously by a community of people you respect, and you are actually likely to get more substantive engagement than if you were a non-top-tier academic publishing in a non-top-tier journal. This kind of intellectual discussion is exciting to a lot of people, and is reason enough in itself. 2. Related to your ideas being taken seriously, they can also steer a community of thousands of people and billions of dollars. It's reasonably common for this to happen, for instance GiveWell changed how they do their cost effectiveness analyses partly as a result of that post by @Froolow that I linked above. There are lots of good examples from LessWrong too, such as Katja Grace's Let's think about sloCAISID1h6001"What makes you stop posting?" could be reframed as "What makes you post in the first place?", and "What might make it easier?" could be reframed as "What might make you publish posts that were more challenging for you (practically or emotionally)?"The quality of many forum posts is very high, including from people who are not paid by a research org to write them and have no direct connection to the community (such as these two). So even if you only factor in the time cost, you would still have to suppose some pretty large benefits to explain why people wr... (read more)Reply8tobytrem8hVery much agree with your suggestions for healthy engagement with posts, thanks for writing them. Also, FWIW, I've seen a lot less of a worrying trend towards criticism than I expected before joining the Forum team 4 months ago. Before joining, I had the idea that Forum users would tear ideas apart, sometimes in kind of harsh ways. I'd also internalised the meme that this was a reason for people not to post. I've been pleasantly surprised by what I've seen. Specifically, if a post seems unsuitable for the Forum, or particularly ill-conceived, it is generally quietly downvoted rather than openly critiqued. In many cases, posts that I thought might be particularly open to criticism were given very helpful, good faith comments. The more critical comments I've seen have been on the work of organisations rather than individuals. Although that might be difficult for the organisations, it also seems more fair-- orgs are being funded for the content they produce, so it matters to all of us that it is as good and correct as it can be. If anyone reading has the opposite impression, I'd love to hear about it (here or in DM). Note: I am the content manager on the Forum, but these are my personal impressions, not those of the team. Animal Charity Evaluators posted Animal Charity Evaluators is doing a live AMA now! 1h ago18Animal Charity Evaluators is doing a live AMA now!Animal Charity EvaluatorsAnimal Charity Evaluators+ 0 more · 1h ago · 1m read0Starting now! Animal Charity Evaluators is holding an AMA on our Movement Grants!The AMA is your chance to ask our team about what projects we’re likely to fund, the application process, how to make a good application, and anything else about the program. Applications close March 17, 11:59 PM PT.Our team members answering questions are:Eleanor McAree, Movement Grants ManagerElisabeth Ormandy, Programs DirectorHolly Baines, Communications ManagerHow to participate? Go to the FAST Forum (make sure you have an account) and ask a question. We look forward to hearing from you! Movement Grants is ACE’s strategic grantmaking program dedicated to building and strengthening the animal advocacy movement. For a limited time, you can DOUBLE your donation to ACE's Movement Grants! By donating to this program, you are investing in the expansion of a broader advocacy movement and a brighter future...Continue readingcynthiaschuck commented on Short agony or long ache: comparing sources of suffering that differ in duration and intensity 2h ago94Short agony or long ache: comparing sources of suffering that differ in duration and intensity cynthiaschuckcynthiaschuck, Wladimir J. Alonso, CianHamilton+ 0 more · 13d ago · 24m read11Cynthia Schuck-Paim; Wladimir J. Alonso; Cian Hamilton (Welfare Footprint Project) OverviewIn assessing animal welfare, it would be immensely beneficial to rely on a cardinal metric that captures the overall affective experience of sentient beings over a period of ...Continue readingcynthiaschuck2h100This is an interesting question, relating to the evolutionary role of pain going beyond protection of the individual survival and immediate reproduction (or that of kin), but affecting the group as a whole. As you said, debilitating pain (i.e., pain that prevents individuals to function normally) for a solitary species may also have different moral implications than for a social species even if the unpleasantness of the pain experience is the same.My impression is that it would be difficult to determine differences in pain aversiveness among species with d... (read more)Reply2cynthiaschuck2hThank you for the detailed comments, it is really nice to see you were so thorough with the text and the studies we cite, these are good points! If we understand you well, with a few exceptions (as in the case of the time trade-off study, [21]), what you mention is that the superlinearity observed could be a by-product of participants of the studies interpreting the designed scales of intensity (even the numerical ones) as not equidistant, hence a non-equidistant plot of aversiveness could, for example, be observed if the relationship between intensity and aversiveness was in fact linear. My impression, however, is that we are referring to different things when we say pain intensity (and this is our fault for not being clearer on the text, we will make the distinction clearer). My understanding is that ‘pain intensity’ is often used simply as a synonym for aversiveness or unpleasantness, as opposed to physical intensity of stimuli/pain signals. As I see it, assessments of pain intensity (unpleasantness) are typically made on what can only be understood as an ordinal scale. Whether evidence on pain unpleasantness is collected with verbal descriptors or numerical descriptors, these unpleasantness scales (i.e. the intensity scales used) can only be interpreted as ordinal exactly because we do not know what type of understanding of the scale study participants have. Even though some authors use the data collected (e.g., pain intensity/unpleasantness ratings in scales from 1-10 or 1-100) and calculate things such as areas under the curve for plots of ‘intensity’ (meant as unpleasantness) ratings x duration, the data is still ordinal for practical purposes and unsuitable for these operations. So the effort in this work was to try and see if it would be possible to make such a conversion of pain unpleasantness (from ordinal to ratio scale), and determine the distance among the categories of unpleasantness on a ratio scale. Thus, in the case of the psychophysics sttobytrem commented on What posts are you thinking about writing? 3h ago33What posts are you thinking about writing?Qtobytremtobytrem+ 0 more · 1d ago · 1m read64I'm posting this to tie in with the Forum's Draft Amnesty Week (March 11-17) plans, but please also use this thread for posts you don't plan to write for draft amnesty. The last time this question was posted, it got some great responses. This post is a companion post...Continue readingtobytrem3h400Drafted! (directly because of upvotes + draft amnesty's lower standards. Would never have finished it otherwise)Reply4Ulrik Horn3hIf anyone else wants to write this I would love for you to do that. I have some rough initial ideas if you want to DM me. If you do, I would love to know when it's published. I guess in general anyone can take any of these ideas and run with but I guess there is some unspoken agreement that the poster of the idea for the blog should perhaps at least be informed that someone intends to write "their idea". Therefore I wanted to make it clear that I am super excited and would encourage someone else to write this up as chances are I will never get around to do so.1Kyle Smith3hI've been thinking very similarly for a while. Would love to read it.PandemicRiskMan posted 6) Speed is The Most Important Variable in Pandemic Risk Management 3h ago16) Speed is The Most Important Variable in Pandemic Risk ManagementPandemicRiskManPandemicRiskMan+ 0 more · 3h ago · 9m read0Pandemics are big and complex and dangerous. There are too many variables to estimate and their interactions are beyond our capacity to model or forecast. We survive these environments by focusing on the key variables, the fundamental drivers of the system.The most important variable in pandemic risk management is speed of reesponse. The quicker we react, the smaller the problem we'll have to solve. The slower we react, the greater the cost and the less likely we are to ever solve it. The speed of your response is the difference between throwing a fire blanket over a pan fire, and watching your whole apartment block go up in flames. No other factor gives us as much leverage over an outbreak.In this post, I will look at speed from three perspectives: reaction time, resource requirements, and complexity. By the end of it, we should be able to see that investments in disease surveillance will...Continue readingResourcesThe EA HandbookThe Introductory EA ProgramDiscover EA groupsOpportunitiesWhy are you reluctant to write on the EA Forum?Posted 1d agoOpen roles at 80,000 Hours: Operations teamPosted 3d agoRunning 200 miles for New IncentivesPosted 4d agoListen to posts anywhereListen onSpotifyListen onApple PodcastsListen onPocket CastsListen onPodcast AddictSend feedback