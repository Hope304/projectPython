Replicate Menu Explore Pricing Docs Blog Changelog Sign in Get started Run AI with an API. Run and fine-tune open-source models. Deploy custom models at scale. All with one line of code. With Replicate you canGenerate imagesGenerate textGenerate videosGenerate musicGenerate speechFine tune modelsRestore imagesstability-ai/sdxlA text-to-image generative AI model that creates beautiful images41M runsstability-ai/sdxlA text-to-image generative AI model that creates beautiful images41M runsai-forever/kandinsky-2.2multilingual text2image latent diffusion model8M runsai-forever/kandinsky-2.2multilingual text2image latent diffusion model8M runsstability-ai/stable-diffusionA latent text-to-image diffusion model capable of generating photo-realistic images given any text input107M runsstability-ai/stable-diffusionA latent text-to-image diffusion model capable of generating photo-realistic images given any text input107M runsfofr/latent-consistency-modelSuper-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet665K runsfofr/latent-consistency-modelSuper-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet665K runsmeta/llama-2-70b-chatA 70 billion parameter language model from Meta, fine tuned for chat completions5M runsmeta/llama-2-70b-chatA 70 billion parameter language model from Meta, fine tuned for chat completions5M runsmistralai/mistral-7b-instruct-v0.1An instruction-tuned 7 billion parameter language model from Mistral804K runsmistralai/mistral-7b-instruct-v0.1An instruction-tuned 7 billion parameter language model from Mistral804K runsmeta/codellama-13bA 13 billion parameter Llama tuned for code completion105K runsmeta/codellama-13bA 13 billion parameter Llama tuned for code completion105K runsanotherjesse/zeroscope-v2-xlZeroscope V2 XL & 576w211K runsanotherjesse/zeroscope-v2-xlZeroscope V2 XL & 576w211K runslucataco/animate-diffAnimate Your Personalized Text-to-Image Diffusion Models152K runslucataco/animate-diffAnimate Your Personalized Text-to-Image Diffusion Models152K runsmeta/musicgenGenerate music from a prompt or melody1M runsmeta/musicgenGenerate music from a prompt or melody1M runsriffusion/riffusionStable diffusion for real-time music generation878K runsriffusion/riffusionStable diffusion for real-time music generation878K runsadirik/styletts2Generates speech from text81K runsadirik/styletts2Generates speech from text81K runslucataco/xtts-v2Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning50K runslucataco/xtts-v2Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning50K runssuno-ai/barkðŸ”Š Text-Prompted Generative Audio Model197K runssuno-ai/barkðŸ”Š Text-Prompted Generative Audio Model197K runsfofr/sdxl-emojiAn SDXL fine-tune based on Apple Emojis3M runsfofr/sdxl-emojiAn SDXL fine-tune based on Apple Emojis3M runsdoriandarko/sdxl-hiroshinagaiSDXL model trained on Hiroshi Nagai's illustrations.13K runsdoriandarko/sdxl-hiroshinagaiSDXL model trained on Hiroshi Nagai's illustrations.13K runsfofr/musicgen-choralMusicGen fine-tuned on chamber choir music2K runsfofr/musicgen-choralMusicGen fine-tuned on chamber choir music2K runstencentarc/gfpganPractical face restoration algorithm for *old photos* or *AI-generated faces*69M runstencentarc/gfpganPractical face restoration algorithm for *old photos* or *AI-generated faces*69M runsnightmareai/real-esrganReal-ESRGAN with optional face correction and adjustable upscale38M runsnightmareai/real-esrganReal-ESRGAN with optional face correction and adjustable upscale38M runsRun modelPythonJavaScriptcURLimport replicate output = replicate.run( "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b", input={ "prompt": "An astronaut riding a rainbow unicorn, cinematic, dramatic" } ) print(output)import Replicate from "replicate"; const replicate = new Replicate(); const output = await replicate.run( "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b", { input: { prompt: "An astronaut riding a rainbow unicorn, cinematic, dramatic" } } ); console.log(output);curl -s -X POST \ -H "Authorization: Token $REPLICATE_API_TOKEN" \ -H "Content-Type: application/json" \ -d $'{ "version": "39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b", "input": { "prompt": "An astronaut riding a rainbow unicorn, cinematic, dramatic" } }' \ https://api.replicate.com/v1/predictionsRun stability-ai/sdxl with an API Thousands of models contributed by our community All the latest open-source models are on Replicate. Theyâ€™re not just demos â€” they all actually work and have production-ready APIs. AI shouldnâ€™t be locked up inside academic papers and demos. Make it real by pushing it to Replicate. Explore models Push a model How it works You can get started with any open-source model with just one line of code. But as you do more complex things, you fine-tune models or deploy your own custom code. Run open-source models Our community has already published thousands of models that are ready to use in production. You can run these with one line of code. Explore models import replicate output = replicate.run( "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b", input={ "width": 768, "height": 768, "prompt": "An astronaut riding a rainbow unicorn, cinematic, dramatic", "refine": "expert_ensemble_refiner", "scheduler": "K_EULER", } ) print(output) Fine-tune models with your own data You can improve open-source models with your own data to create new models that are better suited to specific tasks. Image models like SDXL can generate images of a particular person, object, or style. Fine-tune image models Language models like Llama 2 generate text in a specific style or get better at a particular task. Fine-tune language models Train a model: import replicate training = replicate.trainings.create( version="stability-ai/sdxl:c221b2b8ef527988fb59bf24a8b97c4561f1c671f73bd389f866bfb27c061316", input={ "input_images": "https://my-domain/my-input-images.zip", }, destination="mattrothenberg/sdxl-fine-tuned" ) print(training) This will result in a new model: mattrothenberg/sdxl-fine-tunedA very special, fine-tuned version of SDXL0 runs mattrothenberg/sdxl-fine-tunedA very special, fine-tuned version of SDXL0 runs Then, you can run it with one line of code: output = replicate.run( "mattrothenberg/sdxl-fine-tuned:abcde1234...", input={"prompt": "a photo of TOK riding a rainbow unicorn"}, ) Deploy custom models You arenâ€™t limited to the models on Replicate: you can deploy your own custom models using Cog, our open-source tool for packaging machine learning models. Cog takes care of generating an API server and deploying it on a big cluster in the cloud. We scale up and down to handle demand, and you only pay for the compute that you use. Learn more First, define the environment your model runs in with cog.yaml: build: gpu: true system_packages: - "libgl1-mesa-glx" - "libglib2.0-0" python_version: "3.10" python_packages: - "torch==1.13.1" predict: "predict.py:Predictor" Next, define how predictions are run on your model with predict.py: from cog import BasePredictor, Input, Path import torch class Predictor(BasePredictor): def setup(self): """Load the model into memory to make running multiple predictions efficient""" self.model = torch.load("./weights.pth") # The arguments and types the model takes as input def predict(self, image: Path = Input(description="Grayscale input image") ) -> Path: """Run a single prediction on the model""" processed_image = preprocess(image) output = self.model(processed_image) return postprocess(output) Scale on Replicate Thousands of businesses are building their AI products on Replicate. Your team can deploy an AI feature in a day and scale to millions of users, without having to be machine learning experts. Automatic scale If you get a ton of traffic, Replicate scales up automatically to handle the demand. If you don't get any traffic, we scale down to zero and don't charge you a thing. CPU $0.000100/sec Nvidia T4 GPU $0.000225/sec Nvidia A40 GPU $0.000575/sec Nvidia A40 (Large) GPU $0.000725/sec Nvidia A100 (40GB) GPU $0.001150/sec Nvidia A100 (80GB) GPU $0.001400/sec 8x Nvidia A40 (Large) GPU $0.005800/sec Learn more about pricing Pay for what you use Replicate only bills you for how long your code is running. You don't pay for expensive GPUs when you're not using them. Forget about infrastructure Deploying machine learning models at scale is hard. If you've tried, you know. API servers, weird dependencies, enormous model weights, CUDA, GPUs, batching. Prediction throughput (requests per second) Logging & monitoring Metrics let you keep an eye on how your models are performing, and logs let you zoom in on particular predictions to debug how your model is behaving. Logo Imagine what you can build Autonomous Robots Zero-shot autonomous robots with open source models Paint with AI An iPad app that lets you paint with AI emojis.sh AI Emojis Replicover Find the hottest AI models on Replicate Language Model CLI Language model command line interface Imagine Autonomous Robots Zero-shot autonomous robots with open source models what you Paint with AI An iPad app that lets you paint with AI can emojis.sh AI Emojis Replicover Find the hottest AI models on Replicate build. Language Model CLI Language model command line interface With Replicate and tools like Next.js and Vercel, you can wake up with an idea and watch it hit the front page of Hacker News by the time you go to bed. Get started Logo Machine learning doesnâ€™t need to be so hard. Product Explore Pricing Docs Guides Blog Changelog Community Discord X GitHub Company About Jobs Privacy Terms