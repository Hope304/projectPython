Common Crawl - Open Repository of Web Crawl Data The DataOverviewWeb GraphsLatest CrawlResourcesGet StartedBlogExamplesUse CasesCCBotInfra StatusFAQCommunityResearch PapersMailing List ArchiveCollaboratorsAboutTeamMissionImpactPrivacy PolicyTerms of UseSearchContact UsCommon Crawl maintains a free, open repository of web crawl data that can be used by anyone.Common Crawl is a 501(c)(3) non–profit founded in 2007.‍We make wholesale extraction, transformation and analysis of open web data accessible to researchers.OverviewOver 250 billion pages spanning 15 years.Free and open corpus since 2007.Cited in over 10,000 research papers.3–5 billion new pages added each month.Featured Papers:Enhancing Computational AnalysisZhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Y.K. Li, Y. Wu, Daya GuoDeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language ModelsComputation and LanguageAsier Gutiérrez-Fandiño, David Pérez-Fernández, Jordi Armengol-Estapé, David Griol, Zoraida CallejasesCorpius: A Massive Spanish Crawling CorpusThe Web as a Graph (Master's Thesis)Marius Løvold Jørgensen, UiT Norges Arktiske Universitet BacklinkDB: A Purpose-Built Backlink Database Management SystemInternet Security: Phishing WebsitesAsadullah Safi, Satwinder SinghA Systematic Literature Review on Phishing Website Detection TechniquesSee More on Google ScholarThe DataOverviewWeb GraphsLatest CrawlResourcesGet StartedBlogExamplesUse CasesCCBotInfra StatusFAQCommunityResearch PapersMailing List ArchiveCollaboratorsAboutTeamMissionImpactPrivacy PolicyTerms of Use© 2023 Common Crawl